{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Image Classification Assessment\n",
    "\n",
    "\n",
    "Welcome to your assessment! Follow the instructions in bold below to complete the assessment.\n",
    "\n",
    "If you get stuck, check out the solutions video and notebook. (Make sure to run the solutions notebook before posting a question to the QA forum please, thanks!)\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "**Your task is to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**TASK 1: Run the code below to download the dataset using Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "**TASK 2: Use matplotlib to view an image from the data set. It can be any image from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2043ee7b5f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(single_image,cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**TASK 3: Normalize the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test/x_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_cat_test = to_categorical(y_test,10)\n",
    "y_cat_train = to_categorical(y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**TASK 5: Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPool2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(28,28,1),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**TASK 6: Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 519s 9ms/step - loss: 0.4078 - acc: 0.8543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2043da97a90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_cat_train,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1802 - acc: 0.9365\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1679 - acc: 0.9395\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1579 - acc: 0.9439\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1502 - acc: 0.9469\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1427 - acc: 0.9496\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1397 - acc: 0.9523\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1312 - acc: 0.9551\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1274 - acc: 0.9559\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1238 - acc: 0.9582\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1201 - acc: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c18a60e400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**TASK 7: Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 15s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3231316271662712, 0.8827]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.89      0.84      1000\n",
      "          1       0.99      0.97      0.98      1000\n",
      "          2       0.76      0.87      0.81      1000\n",
      "          3       0.89      0.91      0.90      1000\n",
      "          4       0.78      0.83      0.81      1000\n",
      "          5       0.96      0.98      0.97      1000\n",
      "          6       0.79      0.53      0.63      1000\n",
      "          7       0.95      0.92      0.93      1000\n",
      "          8       0.98      0.97      0.98      1000\n",
      "          9       0.93      0.95      0.94      1000\n",
      "\n",
      "avg / total       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_image_x = x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_image_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "single_image_x = np.expand_dims(single_image_x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_image_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_image_y= y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(single_image_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
